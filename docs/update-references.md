Hereâ€™s a complete, polished documentation section you can add under your project as a technical and strategic justification for the **User Historyâ€“based Preference Update system**. Itâ€™s framed as part of your architecture and also explains *why* itâ€™s a good foundation, especially for new systems without enough ML data yet.

---

# ğŸ§  User Historyâ€“Driven Preference Learning

This section explains the motivation, structure, and rationale behind our lightweight preference update engine based on user interaction history.

---

## ğŸ“Œ Motivation

Building a recommendation system requires an understanding of user intent and evolving interests. While machine learningâ€“based systems often excel at personalization, they require large datasets, long training cycles, and heavy infrastructure.

As our system is **new and rapidly evolving**, we designed a **rule-based, explainable, and scalable heuristic model** that can be used immediately â€” while still being extensible toward ML in the future.

---

## ğŸ§© How It Works

We track user interactions (likes, views, saves, dismisses, shares) across all content and convert them into updated user preferences â€” such as favorite tags, sources, and content types.

---

### ğŸ” Tracked Actions

| Action   | Meaning                                | Weight |
|----------|----------------------------------------|--------|
| view     | User browsed or previewed the content  | +1     |
| like     | User liked or upvoted the content      | +3     |
| save     | User bookmarked the content            | +4     |
| share    | User shared it with others             | +2     |
| dismiss  | User explicitly disliked or skipped it | â€“5     |

Each action contributes a *weight* to the tags, source, and type associated with the content.

---

### ğŸ§® Preference Scoring Formulas

Let:
- \( H_u \) = user history for user \( u \)
- \( A \) = action (like, view, etc.)
- \( w_A \) = weight of action \( A \)
- \( T_c \), \( S_c \), \( Y_c \) = tags, source, and type of content \( c \)

#### 1. **Tag Preference Score**
\[
\text{TagScore}_u(t) = \sum_{(c, A) \in H_u \text{ where } t \in T_c} w_A
\]

#### 2. **Source Preference Score**
\[
\text{SourceScore}_u(s) = \sum_{(c, A) \in H_u \text{ where } S_c = s} w_A
\]

#### 3. **Content Type Preference Score**
\[
\text{TypeScore}_u(y) = \sum_{(c, A) \in H_u \text{ where } Y_c = y} w_A
\]

We then select the **top N** scoring items per category to form the userâ€™s updated preferences.

---

## ğŸ“… Preference Update Job (Scheduled)

This job runs on a **Vercel Cron Job (hourly)** and:

1. Fetches recent `UserHistory`.
2. Joins with `Content` to get tags, source, type.
3. Applies the formula above to compute updated scores.
4. Updates the `UserPreferences` table with:
   - Top tags â†’ `interests`
   - Top sources â†’ `sources`
   - Top content types â†’ `contentTypes`
5. Invalidates the Redis cache for `/api/for-you` to ensure updates reflect immediately.

---

## âœ… Why This Is a Good Approach (Especially Early-Stage)

### âœ… Lightweight & Fast
- No need for training pipelines or GPU inference.
- Easy to understand, modify, and debug.
  
### âœ… Cold Startâ€“Friendly
- Works even when a user has limited interaction data.
- Can bootstrap from a few actions (e.g., likes or dismissals).

### âœ… Scalable Toward ML
- This design logs everything needed for future modeling.
- Once enough data is collected, we can:
  - Learn embeddings from user behavior.
  - Train models to predict CTR or rank content.
  - Move from rule-based to learned scoring.

### âœ… Personalized Yet Transparent
- Developers and analysts can inspect why a piece of content was recommended.
- Useful for auditing, user trust, and content moderation.

---

## ğŸš€ Future Enhancements

- Decay older actions over time (e.g., exponential decay).
- Use implicit signals (scroll depth, hover time).
- Hybridize with collaborative filtering for cross-user recommendations.
- Add an optional ML scoring pipeline using collected history.

---

Let me know if you'd like a visual diagram of this pipeline, or a research-style paragraph to include in a paper or whitepaper.